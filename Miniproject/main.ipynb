{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the nessecary libraries, and add labels to the dataset.\n",
    "Create a CSV file from that new data set and save it as a CSV file.\n",
    "Use that CSV file as the main data set from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   state  county  community        communityname  fold  population  \\\n",
      "0      8     NaN        NaN         Lakewoodcity     1        0.19   \n",
      "1     53     NaN        NaN          Tukwilacity     1        0.00   \n",
      "2     24     NaN        NaN         Aberdeentown     1        0.00   \n",
      "3     34     5.0    81440.0  Willingborotownship     1        0.04   \n",
      "4     42    95.0     6096.0    Bethlehemtownship     1        0.01   \n",
      "\n",
      "   householdsize  racepctblack  racePctWhite  racePctAsian  ...  LandArea  \\\n",
      "0           0.33          0.02          0.90          0.12  ...      0.12   \n",
      "1           0.16          0.12          0.74          0.45  ...      0.02   \n",
      "2           0.42          0.49          0.56          0.17  ...      0.01   \n",
      "3           0.77          1.00          0.08          0.12  ...      0.02   \n",
      "4           0.55          0.02          0.95          0.09  ...      0.04   \n",
      "\n",
      "   PopDens  PctUsePubTrans  PolicCars  PolicOperBudg  LemasPctPolicOnPatr  \\\n",
      "0     0.26            0.20       0.06           0.04                  0.9   \n",
      "1     0.12            0.45        NaN            NaN                  NaN   \n",
      "2     0.21            0.02        NaN            NaN                  NaN   \n",
      "3     0.39            0.28        NaN            NaN                  NaN   \n",
      "4     0.09            0.02        NaN            NaN                  NaN   \n",
      "\n",
      "   LemasGangUnitDeploy  LemasPctOfficDrugUn  PolicBudgPerPop  \\\n",
      "0                  0.5                 0.32             0.14   \n",
      "1                  NaN                 0.00              NaN   \n",
      "2                  NaN                 0.00              NaN   \n",
      "3                  NaN                 0.00              NaN   \n",
      "4                  NaN                 0.00              NaN   \n",
      "\n",
      "   ViolentCrimesPerPop  \n",
      "0                 0.20  \n",
      "1                 0.67  \n",
      "2                 0.43  \n",
      "3                 0.12  \n",
      "4                 0.03  \n",
      "\n",
      "[5 rows x 128 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from zlib import crc32\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "'''\n",
    "#---------read the attribute names first------------------\n",
    "with open('Names.txt', 'r') as file:\n",
    "    attributes = file.readlines()\n",
    "columnNames = [line.split()[-2] for line in attributes if line.startswith('@attribute')]        #we are only interested in the name itself, delete everything else\n",
    "\n",
    "#---------read the data-----------------\n",
    "dataset = pd.read_csv('communities.data', header=None)\n",
    "dataset.columns = columnNames\n",
    "#dataset.to_csv('DatasetWithHeaders', index=False)      #Only need to run this once, so therefore its out\n",
    "'''\n",
    "datasetWithHeaders = pd.read_csv('DatasetWithHeaders', na_values=[\"?\"])  #The new dataset with labels.\n",
    "print(datasetWithHeaders.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many columns contain missing values (denoted with \"?\") and find how much percent of that feature has missing values in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 'NaN' values in column 'county': 58.88%\n",
      "Percentage of 'NaN' values in column 'community': 59.03%\n",
      "Percentage of 'NaN' values in column 'OtherPerCap': 0.05%\n",
      "Percentage of 'NaN' values in column 'LemasSwornFT': 84.00%\n",
      "Percentage of 'NaN' values in column 'LemasSwFTPerPop': 84.00%\n",
      "Percentage of 'NaN' values in column 'LemasSwFTFieldOps': 84.00%\n",
      "Percentage of 'NaN' values in column 'LemasSwFTFieldPerPop': 84.00%\n",
      "Percentage of 'NaN' values in column 'LemasTotalReq': 84.00%\n",
      "Percentage of 'NaN' values in column 'LemasTotReqPerPop': 84.00%\n",
      "Percentage of 'NaN' values in column 'PolicReqPerOffic': 84.00%\n",
      "Percentage of 'NaN' values in column 'PolicPerPop': 84.00%\n",
      "Percentage of 'NaN' values in column 'RacialMatchCommPol': 84.00%\n",
      "Percentage of 'NaN' values in column 'PctPolicWhite': 84.00%\n",
      "Percentage of 'NaN' values in column 'PctPolicBlack': 84.00%\n",
      "Percentage of 'NaN' values in column 'PctPolicHisp': 84.00%\n",
      "Percentage of 'NaN' values in column 'PctPolicAsian': 84.00%\n",
      "Percentage of 'NaN' values in column 'PctPolicMinor': 84.00%\n",
      "Percentage of 'NaN' values in column 'OfficAssgnDrugUnits': 84.00%\n",
      "Percentage of 'NaN' values in column 'NumKindsDrugsSeiz': 84.00%\n",
      "Percentage of 'NaN' values in column 'PolicAveOTWorked': 84.00%\n",
      "Percentage of 'NaN' values in column 'PolicCars': 84.00%\n",
      "Percentage of 'NaN' values in column 'PolicOperBudg': 84.00%\n",
      "Percentage of 'NaN' values in column 'LemasPctPolicOnPatr': 84.00%\n",
      "Percentage of 'NaN' values in column 'LemasGangUnitDeploy': 84.00%\n",
      "Percentage of 'NaN' values in column 'PolicBudgPerPop': 84.00%\n",
      "['county', 'community', 'OtherPerCap', 'LemasSwornFT', 'LemasSwFTPerPop', 'LemasSwFTFieldOps', 'LemasSwFTFieldPerPop', 'LemasTotalReq', 'LemasTotReqPerPop', 'PolicReqPerOffic', 'PolicPerPop', 'RacialMatchCommPol', 'PctPolicWhite', 'PctPolicBlack', 'PctPolicHisp', 'PctPolicAsian', 'PctPolicMinor', 'OfficAssgnDrugUnits', 'NumKindsDrugsSeiz', 'PolicAveOTWorked', 'PolicCars', 'PolicOperBudg', 'LemasPctPolicOnPatr', 'LemasGangUnitDeploy', 'PolicBudgPerPop']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#columnsWithQuestionMark = [column for column in datasetWithHeaders.columns if datasetWithHeaders[column].astype(str).str.contains('\\\\NaN').any()]\n",
    "columnsWithNaN = [column for column in datasetWithHeaders.columns if datasetWithHeaders[column].isna().any()]\n",
    "columnPercentages = {}\n",
    "listOfFeaturesWithMissingValue = []\n",
    "# Calculate the percentage of \"?\" in each column and store the results\n",
    "for column in columnsWithNaN:\n",
    "    percentQuestionMark = (datasetWithHeaders[column].isna().mean() * 100)\n",
    "    columnPercentages[column] = percentQuestionMark\n",
    "    listOfFeaturesWithMissingValue.append(column)\n",
    "#Print the percentages for columns with \"?\"\n",
    "for column, percentage in columnPercentages.items():\n",
    "    print(f\"Percentage of 'NaN' values in column '{column}': {percentage:.2f}%\")\n",
    "\n",
    "print(listOfFeaturesWithMissingValue)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25 features have missing data, however 22 of the features have 84% of their data missing so we'll remove those from the list.\n",
    "For \"OtherPerCap\" (which is referring to per capita income of whose ethnicity is other than the ones listed in the dataset) we will\n",
    "use the mean and fill that in for the missing values.\n",
    "We will also get rid of any \"Not predictive\" features except for state. These are:\n",
    "county, community, communityname and fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values in any column.\n"
     ]
    }
   ],
   "source": [
    "#-------------Only run this block once, otherwise the columns with the missing values will come back--------\n",
    "\n",
    "\n",
    "\n",
    "listOfFeaturesWithMissingValue = listOfFeaturesWithMissingValue[3:]\n",
    "newDataSet = datasetWithHeaders.drop(columns=listOfFeaturesWithMissingValue)\n",
    "cols = ['OtherPerCap']\n",
    "newDataSet.fillna(newDataSet[cols].mean(), inplace=True)\n",
    "newDataSet = newDataSet.drop(columns=['county','community','communityname','fold'])\n",
    "newDataSet.to_csv('new_dataset.csv', index=False)\n",
    "\n",
    "columnsWithMissingValues = newDataSet.columns[newDataSet.isna().any()].tolist()\n",
    "\n",
    "# Check if there are any missing values\n",
    "if columnsWithMissingValues:\n",
    "    print(\"Columns with missing values:\", columnsWithMissingValues)\n",
    "else:\n",
    "    print(\"No missing values in any column.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a supervised task. Its a multiple regression (a univariate regression because we are only trying to predict a single value) task, and we will use batch learning.\n",
    "\n",
    "We will start with setting aside 20% of the data for Testing. This will be chosen randomly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of newTrainSet: 1595\n",
      "Length of newTestSet: 399\n",
      "      state county community        communityname  fold  population  \\\n",
      "1378     28      ?         ?          Jacksoncity     7        0.30   \n",
      "1826     34     31     60090  PomptonLakesborough    10        0.00   \n",
      "678      12      ?         ?            Daniacity     4        0.00   \n",
      "1083     25      3     46225       NorthAdamscity     6        0.01   \n",
      "1558      5      ?         ?           Bentoncity     8        0.01   \n",
      "\n",
      "      householdsize  racepctblack  racePctWhite  racePctAsian  ...  \\\n",
      "1378           0.48          1.00          0.14          0.03  ...   \n",
      "1826           0.45          0.01          0.96          0.09  ...   \n",
      "678            0.23          0.61          0.50          0.03  ...   \n",
      "1083           0.38          0.03          0.97          0.03  ...   \n",
      "1558           0.41          0.08          0.93          0.01  ...   \n",
      "\n",
      "      PctForeignBorn  PctBornSameState  PctSameHouse85  PctSameCity85  \\\n",
      "1378            0.03              0.87            0.60           0.77   \n",
      "1826            0.23              0.72            0.77           0.79   \n",
      "678             0.41              0.24            0.50           0.69   \n",
      "1083            0.10              0.85            0.58           0.76   \n",
      "1558            0.02              0.77            0.61           0.70   \n",
      "\n",
      "      PctSameState85  LandArea  PopDens  PctUsePubTrans  LemasPctOfficDrugUn  \\\n",
      "1378            0.81      0.32     0.15            0.10                 0.41   \n",
      "1826            0.87      0.01     0.30            0.18                 0.00   \n",
      "678             0.59      0.01     0.21            0.13                 0.00   \n",
      "1083            0.79      0.06     0.07            0.10                 0.00   \n",
      "1558            0.74      0.04     0.10            0.00                 0.00   \n",
      "\n",
      "      ViolentCrimesPerPop  \n",
      "1378                 0.59  \n",
      "1826                 0.02  \n",
      "678                  1.00  \n",
      "1083                 0.24  \n",
      "1558                 0.19  \n",
      "\n",
      "[5 rows x 106 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "newTrainset, newTestSet = train_test_split(newDataSet, test_size=0.2, random_state=42)\n",
    "print(f\"Length of newTrainSet: {len(newTrainset)}\") #Should be roughly 80% of the data\n",
    "print(f\"Length of newTestSet: {len(newTestSet)}\") #Should be roughly 20% of the data\n",
    "print(newTrainset.head())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
